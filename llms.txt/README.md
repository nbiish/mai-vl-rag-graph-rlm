# VL-RAG-Graph-RLM Documentation

Version: 0.2.0 (Feb 12, 2026)

## Overview

This folder contains comprehensive documentation for the **VL-RAG-Graph-RLM** (Vision-Language RAG Graph Recursive Language Model) framework ‚Äî a unified multimodal document analysis system with **named persistent knowledge collections**, **accuracy-first retrieval**, and **18 LLM provider templates** with automatic fallback.

The system processes documents (PPTX, PDF, TXT, MD, Video, Audio) through a full 6-pillar pipeline: Qwen3-VL vision-language embeddings ‚Üí hybrid RAG with RRF fusion ‚Üí cross-attention reranking ‚Üí knowledge graph extraction ‚Üí recursive LLM reasoning ‚Üí markdown report generation. All model loading uses **sequential load-use-free** memory management (peak ~6.7 GB on a 40-min video).

## What's New (v0.2.0 ‚Äî Feb 12, 2026)

### üß™ Modal Research Provider (New!)
**Free GLM-5 745B frontier inference** via Modal Research's OpenAI-compatible endpoint:
- **Model:** `zai-org/GLM-5-FP8` ‚Äî 745B parameters (44B active), MoE architecture, MIT license
- **Endpoint:** `https://api.us-west-2.modal.direct/v1` ‚Äî runs on 8√óB200 GPUs via SGLang
- **Performance:** 30-75 tok/s per user, frontier-class reasoning
- **Status:** Experimental (free tier: 1 concurrent request, may have downtime)
- **Get key:** https://modal.com/glm-5-endpoint

```bash
vrlmrag document.pptx --provider modalresearch
# Or use auto mode ‚Äî modalresearch is first in hierarchy
vrlmrag document.pptx
```

### üîë Fallback API Key System (New!)
**Multi-account support** with automatic fallback when primary keys fail:
- **Pattern:** `{PROVIDER}_API_KEY_FALLBACK` ‚Äî every provider supports this suffix
- **Use cases:** Credit distribution, rate limit mitigation, account redundancy
- **Four-tier resilience:** Primary key ‚Üí Fallback key ‚Üí Model fallback ‚Üí Provider hierarchy

```bash
# Example: Two OpenRouter accounts
OPENROUTER_API_KEY=sk-or-v1-primary-key
OPENROUTER_API_KEY_FALLBACK=sk-or-v1-secondary-key
```

**Implementation:**
- All OpenAI-compatible providers (14+ providers via `OpenAICompatibleClient`)
- Anthropic/AnthropicCompatible clients
- Gemini client
- Fallback key promoted to primary after successful retry (session persistence)

### üéØ Omni Model Fallback Chain (New!)
Three-tier resilient multimodal processing for images, audio, and video:
- **Primary:** ZenMux `inclusionai/ming-flash-omni-preview` ‚Äî text, image, audio, video
- **Secondary:** ZenMux `gemini/gemini-3-flash-preview` ‚Äî fallback for all modalities
- **Tertiary:** OpenRouter `google/gemini-3-flash-preview` ‚Äî final omni fallback
- **Legacy VLM:** OpenRouter `moonshotai/kimi-k2.5` ‚Äî images/video only (no audio)

Audio transcription now routes through the full omni chain ‚Äî no more silent failures when the primary omni model is unavailable.

### üì¶ Collection Management (New!)
- **Export/Import** ‚Äî `--collection-export PATH` and `--collection-import PATH` for portable tar.gz archives
- **Collection Merge** ‚Äî `--collection-merge SRC` merges one collection into another
- **Collection Tagging** ‚Äî `--collection-tag TAG` and `--collection-untag TAG` for organization
- **Collection Search** ‚Äî `--collection-search QUERY` and `--collection-search-tags TAGS` to find collections
- **Statistics Dashboard** ‚Äî `--collection-stats` and `--global-stats` for detailed analytics

### üîç RAG Improvements
- **BM25 keyword search** ‚Äî Replaced simple token-overlap with state-of-the-art BM25 algorithm via `rank-bm25`
- **Graph-augmented retrieval** ‚Äî `--graph-augmented` traverses KG edges for context expansion (`--graph-hops N`)
- **Multi-query retrieval** ‚Äî `--multi-query` generates sub-queries via RLM for broader recall
- **Configurable RRF weights** ‚Äî `--rrf-dense-weight` and `--rrf-keyword-weight` tune fusion balance
- **SQLite backend** ‚Äî `--use-sqlite` flag enables persistent vector store with better performance

### üìä Output & UX Enhancements
- **JSON output** ‚Äî `--format json` for machine-readable results (default: markdown)
- **Log level control** ‚Äî `--verbose` and `--quiet` for output verbosity
- **Progress bars** ‚Äî tqdm integration for embedding/search operations

### üéØ Smart Defaults (New!)
- **Configuration profiles** ‚Äî `--profile {fast,balanced,thorough,comprehensive}` presets
- **Comprehensive by default** ‚Äî All best features enabled automatically (multi-query, graph-augmented, deep reasoning)
- **API hierarchy default** ‚Äî Provider auto-fallback enabled by default (set keys in .env)
- **MCP streamlined server** ‚Äî 4 consolidated tools instead of 11+ for reduced context usage

### ü§ñ New Providers
- **Ollama** ‚Äî Local LLM inference support (`--provider ollama`)

### üìÑ Enhanced Document Processing
- **PDF support** ‚Äî PyMuPDF extracts text and images from PDF documents
- **DOCX support** ‚Äî python-docx extracts text and tables from Word documents
- **CSV/Excel support** ‚Äî Tabular data ingestion with natural language row chunking
- **Sliding window chunking** ‚Äî Configurable `--chunk-size` and `--chunk-overlap`

### Knowledge Graph Enhancements
- **Graph visualization** ‚Äî `--export-graph PATH` exports to Mermaid, Graphviz (DOT), or NetworkX formats
- **Graph statistics** ‚Äî `--graph-stats` shows entity counts, relationship stats, type distribution
- **Entity deduplication** ‚Äî `--deduplicate-kg` merges similar entities with configurable `--dedup-threshold`
- **NetworkX serialization** ‚Äî Export structured graphs for external analysis

### Model Management
- **Model comparison** ‚Äî `--model-compare OLD_MODEL` compares embeddings between model versions
- **Compatibility checking** ‚Äî `--check-model MODEL` verifies collection compatibility before migration
- **Quality assessment** ‚Äî `--quality-check` RLM-powered evaluation of embedding retrieval quality

```bash
# Process PDF with sliding window chunking
vrlmrag document.pdf --chunk-size 500 --chunk-overlap 50

# Export knowledge graph as Mermaid diagram
vrlmrag -c research --export-graph graph.mmd --graph-format mermaid

# Show graph statistics and deduplication report
vrlmrag -c research --graph-stats --dedup-report

# Run with multi-query retrieval for better recall
vrlmrag ./docs -q "Key findings?" --multi-query
```

### Named Persistent Collections (v0.1.1)
Build named, location-independent knowledge stores that persist inside the codebase.

```bash
vrlmrag -c research --add ./papers/          # add docs to a collection
vrlmrag -c research -q "Key findings?"       # query a collection
vrlmrag -c research -c code -q "How?"        # blend multiple collections
```

## Documentation Files

| File | Purpose |
|------|---------|
| **[README.md](README.md)** | Documentation index ‚Äî quick navigation, what's new, key capabilities |
| **[PRD.md](PRD.md)** | Product Requirements ‚Äî six-pillar architecture, 17 providers, CLI, collections, future plans |
| **[ARCHITECTURE.md](ARCHITECTURE.md)** | System architecture ‚Äî diagrams, component map, pipeline flow, collection internals, CLI reference |
| **[RULES.md](RULES.md)** | Coding standards ‚Äî always/never patterns, collection rules, device detection, provider-specific rules |
| **[TODO.md](TODO.md)** | Roadmap ‚Äî v0.2.0 plans, collection enhancements, completed items |
| **[CONTRIBUTING.md](CONTRIBUTING.md)** | Contributor guide ‚Äî adding providers, extending collections, testing |
| **[CHANGELOG.md](CHANGELOG.md)** | Version history ‚Äî v0.1.0 initial, v0.1.1 collections, v0.1.2 audio/video/memory |
| **[SECURITY.md](../SECURITY.md)** | Local security orchestration ‚Äî secret scanning, sanitization, OWASP compliance |

## Quick Navigation

### For Users
- **Getting started:** [PRD.md](PRD.md) ‚Üí system overview, CLI examples, provider list
- **CLI reference:** [ARCHITECTURE.md](ARCHITECTURE.md) ‚Üí all flags, collection commands, environment variables
- **Collections:** [ARCHITECTURE.md ¬ß Named Persistent Collections](ARCHITECTURE.md) ‚Üí storage layout, blending, scripting
- **What's new:** [CHANGELOG.md](CHANGELOG.md) ‚Üí v0.1.1 features

### For Contributors
- **Adding providers:** [CONTRIBUTING.md](CONTRIBUTING.md) ‚Üí 5-step guide with template
- **Extending collections:** [CONTRIBUTING.md](CONTRIBUTING.md) ‚Üí collection manager API
- **Coding standards:** [RULES.md](RULES.md) ‚Üí always/never patterns, collection rules
- **Roadmap:** [TODO.md](TODO.md) ‚Üí what's planned, what's done

### For Developers
- **Architecture deep-dive:** [ARCHITECTURE.md](ARCHITECTURE.md) ‚Üí system diagram, data flow, component map
- **Collection internals:** [ARCHITECTURE.md](ARCHITECTURE.md) ‚Üí `collections.py` API, metadata schema, blending mechanics
- **Pipeline flow:** [ARCHITECTURE.md](ARCHITECTURE.md) ‚Üí `_run_vl_rag_query()` template pattern with retrieval instructions
- **Provider rules:** [RULES.md](RULES.md) ‚Üí device detection, Qwen3-VL patterns, fallback behavior

## The Six-Pillar Architecture

Every template, query, and collection operation exercises all six pillars:

| # | Pillar | Component | Cost |
|---|--------|-----------|------|
| 1 | **VL** | Qwen3-VL-Embedding-2B ‚Äî unified text + image + video + audio embeddings | FREE (local) |
| 2 | **RAG** | Hybrid search (dense cosine + keyword) with RRF fusion | FREE (local) |
| 3 | **Reranker** | Qwen3-VL-Reranker-2B ‚Äî cross-attention relevance scoring | FREE (local) |
| 4 | **Graph** | Knowledge graph extraction via RLM (typed entities + relationships) | LLM cost |
| 5 | **RLM** | Recursive Language Model with sandboxed REPL | LLM cost |
| 6 | **Report** | Markdown report with sources, scores, and metadata | FREE |

See **[PRD.md](PRD.md)** for the full architecture specification or **[ARCHITECTURE.md](ARCHITECTURE.md)** for implementation details.

## Key Capabilities

### Three Operating Modes

| Mode | Command | Description |
|------|---------|-------------|
| **Default** | `vrlmrag <path>` | Process docs ‚Üí embed ‚Üí query ‚Üí report |
| **Interactive** | `vrlmrag -i <path>` | Load VL models once, query continuously, `/add` docs on the fly |
| **Collection** | `vrlmrag -c <name> -q "..."` | Query named persistent knowledge stores, blend multiple collections |

### Persistence & Deduplication

All modes persist embeddings and knowledge graphs automatically:
- **Path-local store:** `.vrlmrag_store/` next to input (default and interactive modes)
- **Named collections:** `collections/<name>/` inside the codebase (collection mode)
- **SHA-256 dedup:** Only new/changed content gets re-embedded
- **KG merging:** Knowledge graph grows across runs, never overwrites
- **Provider-agnostic:** Embeddings are local Qwen3-VL; any LLM provider can query any store

### Provider Resilience

18 providers with automatic **four-tier fallback**:
1. **API key fallback** ‚Äî primary key fails ‚Üí retry with `{PROVIDER}_API_KEY_FALLBACK` (same provider, different account)
2. **Model fallback** ‚Äî primary model fails ‚Üí retry with fallback model (same provider, same key)
3. **Provider fallback** ‚Äî all retries fail ‚Üí try next provider in hierarchy
4. **z.ai five-tier** ‚Äî Coding Plan endpoint ‚Üí Normal endpoint ‚Üí fallback key ‚Üí model fallback ‚Üí hierarchy

Default hierarchy: `modalresearch ‚Üí sambanova ‚Üí nebius ‚Üí groq ‚Üí cerebras ‚Üí zai ‚Üí zenmux ‚Üí openrouter ‚Üí ...`

## Future Plans

See **[TODO.md](TODO.md)** for the full roadmap. Key upcoming features:

- **Collection enhancements:** Remote sync, multi-user access
- **Testing:** Integration tests, CI pipeline, benchmark suite
- **Providers:** vLLM (self-hosted), more local LLM options
- **Advanced RAG:** Hybrid fusion, query expansion, cross-collection search

## Version

Current release: **v0.2.0** (2026-02-12)

See **[CHANGELOG.md](CHANGELOG.md)** for full release notes.

## Project Links

- Main README: `../README.md`
- Collections module: `../src/vl_rag_graph_rlm/collections.py`
- CLI entry point: `../src/vrlmrag.py`
- Templates: `../templates/`
- Source Code: `../src/vl_rag_graph_rlm/`
