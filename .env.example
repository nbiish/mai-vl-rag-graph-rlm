# API Keys for Unified RLM
# Get keys from respective provider dashboards

# =====================================================
# OpenAI-Compatible Providers (Generic)
# =====================================================
# Any provider with OpenAI-compatible API (custom base URL)
# Examples: Groq, Mistral, Fireworks, Together, DeepSeek, etc.
OPENAI_COMPATIBLE_API_KEY=your_api_key_here
OPENAI_COMPATIBLE_BASE_URL=https://api.example.com/v1
OPENAI_COMPATIBLE_MODEL=your-model-name

# =====================================================
# OpenAI
# =====================================================
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1  # Optional: for custom endpoints
# OPENAI_MODEL=gpt-4o-mini  # Optional: defaults to gpt-4o-mini

# =====================================================
# Azure OpenAI
# =====================================================
AZURE_OPENAI_API_KEY=your_azure_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-02-01
# AZURE_OPENAI_MODEL=gpt-4o  # Optional: set your deployed model name

# =====================================================
# Anthropic
# =====================================================
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_BASE_URL=https://api.anthropic.com  # Optional: for custom endpoints/proxies
# ANTHROPIC_MODEL=claude-4.5-haiku  # Optional: defaults to claude-3-5-haiku

# =====================================================
# Anthropic-Compatible Providers (Generic)
# =====================================================
# Any provider with Anthropic-compatible API
ANTHROPIC_COMPATIBLE_API_KEY=your_api_key_here
ANTHROPIC_COMPATIBLE_BASE_URL=https://api.example.com
ANTHROPIC_COMPATIBLE_MODEL=your-model-name

# =====================================================
# OpenRouter
# =====================================================
OPENROUTER_API_KEY=your_openrouter_api_key_here
# OPENROUTER_MODEL=upstage/solar-pro-3:free  # Optional: defaults to minimax/minimax-m2.1
# OPENROUTER_RECURSIVE_MODEL=openrouter/pony-alpha  # Optional: for recursive calls

# =====================================================
# ZenMux
# =====================================================
ZENMUX_API_KEY=your_zenmux_api_key_here
# ZENMUX_MODEL=moonshotai/kimi-k2.5  # Optional: defaults to ernie-5.0-thinking-preview
# ZENMUX_RECURSIVE_MODEL=z-ai/glm-4.7  # Optional: for recursive calls

# =====================================================
# z.ai (Zhipu AI - GLM series)
# =====================================================
ZAI_API_KEY=your_zai_api_key_here
# ZAI_MODEL=glm-4.7  # Optional: defaults to glm-4.7
# ZAI_RECURSIVE_MODEL=glm-4.7-flash  # Optional: for recursive calls

# =====================================================
# Google
# =====================================================
GOOGLE_API_KEY=your_google_api_key_here
# GOOGLE_MODEL=gemini-3-pro  # Optional: defaults to gemini-1.5-flash
# GOOGLE_RECURSIVE_MODEL=gemini-3-flash  # Optional: for recursive calls

# =====================================================
# Other Popular Providers
# =====================================================

# Groq
GROQ_API_KEY=your_groq_api_key_here
# GROQ_MODEL=llama-3.3-70b-versatile  # Optional: defaults to llama-3.3-70b-versatile

# Cerebras
CEREBRAS_API_KEY=your_cerebras_api_key_here
# CEREBRAS_MODEL=llama-3.3-70b  # Optional: defaults to llama-3.3-70b
# Other options: llama3.1-8b, qwen-3-32b, zai-glm-4.7

# Mistral AI
MISTRAL_API_KEY=your_mistral_api_key_here
# MISTRAL_MODEL=mistral-large-latest  # Optional: set your preferred model

# Fireworks AI
FIREWORKS_API_KEY=your_fireworks_api_key_here
# FIREWORKS_MODEL=accounts/fireworks/models/llama-v3p1-70b-instruct  # Optional

# Together AI
TOGETHER_API_KEY=your_together_api_key_here
# TOGETHER_MODEL=meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo  # Optional

# DeepSeek
DEEPSEEK_API_KEY=your_deepseek_api_key_here
# DEEPSEEK_MODEL=deepseek-chat  # Optional: defaults to deepseek-chat

# =====================================================
# SambaNova Cloud
# =====================================================
SAMBANOVA_API_KEY=your_sambanova_api_key_here
# SAMBANOVA_MODEL=DeepSeek-V3.2  # Optional: defaults to DeepSeek-V3.2

# =====================================================
# Nebius Token Factory
# =====================================================
# Nebius advantage: NO daily token limits (unlike SambaNova's 200K TPD)
# Get API key: https://tokenfactory.nebius.com
NEBIUS_API_KEY=your_nebius_api_key_here
# NEBIUS_MODEL=MiniMaxAI/MiniMax-M2.1  # Optional: defaults to MiniMaxAI/MiniMax-M2.1
# Other options: zai-org/GLM-4.7-FP8, deepseek-ai/DeepSeek-R1-0528, meta-llama/Meta-Llama-3.1-70B-Instruct
# NEBIUS_CONTEXT_WINDOW=128000  # Optional: context window in tokens (default: 128000)
# With 128K tokens, CLI can use ~100K char context vs ~8K for SambaNova

# =====================================================
# Embedding Configuration
# =====================================================
# HuggingFace token for downloading models (optional)
HF_TOKEN=your_huggingface_token_here
